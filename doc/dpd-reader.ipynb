{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def parse_and_generate_csv(input_filename, nodes_csv_filename, edges_csv_filename):\n",
    "    with \\\n",
    "        open(input_filename, \"r\") as input_file,\\\n",
    "        open(nodes_csv_filename, \"w\", newline=\"\") as nodes_csv,\\\n",
    "        open(edges_csv_filename, \"w\", newline=\"\") as edges_csv:\n",
    "        input_text = input_file.read()\n",
    "        nodes_writer = csv.writer(nodes_csv)\n",
    "        edges_writer = csv.writer(edges_csv)\n",
    "\n",
    "        nodes_writer.writerow([\"id\", \"name\", \"body\", \"kind\", \"prop\", \"path\"])\n",
    "        edges_writer.writerow([\"source\", \"target\", \"weight\"])\n",
    "\n",
    "        node_data = {}\n",
    "        for line in input_text.strip().split(\"\\n\"):\n",
    "            if line.startswith(\"N:\"):\n",
    "                match = re.match(r'N:\\s+(\\d+)\\s+\"([^\"]+)\"\\s+\\[([^\\]]+)\\]\\s*;', line)\n",
    "                if match:\n",
    "                    node_id, node_name, node_attributes = match.group(1), match.group(2), match.group(3)\n",
    "                    attributes = dict(re.findall(r'(\\w+)=\"?(\\w+)\"?', node_attributes))\n",
    "                    node_data[node_id] = {\"name\": node_name, **attributes}\n",
    "                    data = node_data[node_id]\n",
    "                    nodes_writer.writerow([\n",
    "                        node_id,\n",
    "                        data[\"name\"],\n",
    "                        data.get(\"body\", \"\"),\n",
    "                        data.get(\"kind\", \"\"),\n",
    "                        data.get(\"prop\", \"\"),\n",
    "                        data.get(\"path\", \"\")\n",
    "                    ])\n",
    "\n",
    "            elif line.startswith(\"E:\"):\n",
    "                match = re.match(r'E:\\s+(\\d+)\\s+(\\d+)\\s+\\[([^\\]]+)\\]\\s*;', line)\n",
    "                if match:\n",
    "                    source_id, target_id, edge_attributes = match.group(1), match.group(2), match.group(3)\n",
    "                    attributes = dict(re.findall(r'(\\w+)=(\\w+)', edge_attributes))\n",
    "                    edges_writer.writerow([source_id, target_id, attributes.get(\"weight\", \"\")])\n",
    "\n",
    "# Example usage\n",
    "parse_and_generate_csv(\"_build/default/catala.dpd\", \"data/nodes.csv\", \"data/edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "\n",
    "def load_csv_to_networkx(nodes_csv_filename, edges_csv_filename):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    with open(nodes_csv_filename, \"r\") as nodes_csv:\n",
    "        nodes_reader = csv.reader(nodes_csv)\n",
    "        next(nodes_reader)  # Skip the header\n",
    "        for row in nodes_reader:\n",
    "            node_id, name, body, kind, prop, path = row\n",
    "            G.add_node(node_id, name=name, body=body, kind=kind, prop=prop, path=path)\n",
    "\n",
    "    with open(edges_csv_filename, \"r\") as edges_csv:\n",
    "        edges_reader = csv.reader(edges_csv)\n",
    "        next(edges_reader)  # Skip the header\n",
    "        for row in edges_reader:\n",
    "            source, target, weight = row\n",
    "            G.add_edge(source, target, weight=weight)\n",
    "\n",
    "    return G\n",
    "\n",
    "graph = load_csv_to_networkx(\"data/nodes.csv\", \"data/edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nx.is_directed_acyclic_graph(graph)\n",
    "\n",
    "roots = [\n",
    "  \"simulation_cred_sred\",\n",
    "  \"simulation_sred_cred\",\n",
    "  \"preservation\",\n",
    "  \"progress\",\n",
    "  \"cred_stack_drop\",\n",
    "  \"correction_continuations\",\n",
    "  \"correction_small_steps\",\n",
    "  \"correctness\",\n",
    "  \"cred_deterministic\",\n",
    "  \"sred_deterministic\"\n",
    "]\n",
    "\n",
    "u = set()\n",
    "name_to_id = {v: k for k, v in dict(graph.nodes(data=\"name\")).items()}\n",
    "for r in roots:\n",
    "  u |= nx.algorithms.dag.descendants(graph, name_to_id[r])\n",
    "  u |= {name_to_id[r]}\n",
    "\n",
    "# print(len(u))\n",
    "# print(len(graph.nodes()))\n",
    "# print(len(set(graph.nodes()) - u))\n",
    "ns = []\n",
    "for to_clear in set(graph.nodes()) - u:\n",
    "  n = graph.nodes()[to_clear]\n",
    "  if n[\"kind\"] == \"construct\":\n",
    "    continue\n",
    "  if n[\"name\"].endswith(\"_sind\"):\n",
    "    continue\n",
    "  if n[\"name\"].endswith(\"_rec\"):\n",
    "    continue\n",
    "  if n[\"name\"].endswith(\"_rect\"):\n",
    "    continue\n",
    "  if n[\"name\"].endswith(\"_ind\"):\n",
    "    continue\n",
    "  if n[\"path\"] == \"sequences\":\n",
    "    continue\n",
    "  ns.append(n)\n",
    "\n",
    "for n in sorted((n[\"path\"] + \".\" + n[\"name\"] for n in ns)):\n",
    "  print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
